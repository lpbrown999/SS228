[DEFAULT]
#check networklib, rewardlib
model = 1
reward_function = 1

#Default folders
weightFolderRoot = weights
logFolderRoot = logs

#size of state vector, number of possible outputs
inputDim = 32				
outputDim = 63

#exploration strategies
explStrat = softmax
explParam = 1000




#Styles: none, play or random
#Actors: AI or Human
[Agent1]
actor = AI
style = play

weightFolder = Agent1Weights
weightFile = test_weights.h5

updateWeight = False

logFolder = Agent1Logs
logFile = LVL4_DELETE_ME2.csv

[Agent2]
actor = Human
style = play

weightFolder = Agent2Weights
weightFile = test_weights.h5

updateWeight = False

logFolder = Agent2Logs
logFile = LVL4_DELETE_ME.csv

[NNLearning]
logFile = Agent1LogRandOvernight.csv
logFolder = Agent1Logs

weightFile = test_weights.h5
weightFolder = Agent1Weights

gamma = .99999
iterations = 1
