[DEFAULT]
#check networklib, rewardlib
model = 1
reward_function = 1

#Default folders
weightFolderRoot = weights
logFolderRoot = logs

#size of state vector, number of possible outputs
inputDim = 32				
outputDim = 63

#exploration strategies
explStrat = epsgreedy
explParam = .10

#Styles: none, play or random
#Actors: AI or Human
[Agent1]
actor = AI
style = play

weightFolder = Agent1Weights
weightFile = freshStart.h5

updateWeight = True

logFolder = Agent1Logs
logFile = testingNN.csv

[Agent2]
actor = Human
style = play

weightFolder = Agent2Weights
weightFile = test_weights.h5

updateWeight = True

logFolder = Agent2Logs
logFile = human.csv

[NNLearning]
logFile = Agent1LogRandOvernight.csv
logFolder = Agent1Logs

weightFile = test_weights.h5
weightFolder = Agent1Weights

alpha = .001
gamma = .99999
iterations = 1
