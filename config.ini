[DEFAULT]
#check betalib, rewardlib
beta_function = 3
reward_function = 3

thetaFolderRoot = thetas
logFolderRoot = logs
numActions = 63

#Global exploration strategies
explStrat = softmax
explParam = 1000

#Styles: none, play or random
#Actors: AI or Human
[Agent1]
actor = AI
style = play

thetaFolder = fighter_11_30
thetaFile = lvl3_lam_200_lvl1prior.npy

updateTheta = False

logFile = LVL4_DELETE_ME2.csv
logFolder = Agent1Logs


[Agent2]
actor = Human
style = play

thetaFolder = fighter_11_30
thetaFile = lvl4_lam_200_lvl3prior_final.npy

updateTheta = False

logFile = LVL4_DELETE_ME.csv
logFolder = Agent2Logs


[BatchLearn]
#Prior is either none or a thing

thetaFolder = fighter_11_29

thetaPrior  = none
thetaOutput = afternoon.npy

logFile = FighterAgent1LogsDAY.csv
logFolder = Agent1Logs

alpha = .01
gamma = .95		
iterations = 20
