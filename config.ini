[DEFAULT]
#check betalib, rewardlib
beta_function = 1
reward_function = 1

thetaFolderRoot = thetas
logFolderRoot = logs
numActions = 54

#Global exploration strategies
explStrat = softmax
explParam = 20

#Styles: none, play or random
#Actors: AI or Human
[Agent1]
actor = AI
style = play

thetaFolder = jumper_11_21
thetaFile = empty_b1_r1.npy

updateTheta = True

logFile = Agent1LogOvernightNew.csv
logFolder = Agent1Logs


[Agent2]
actor = AI
style = none

thetaFolder = jumper_11_21
thetaFile = jumper_b1_r1.npy

updateTheta = False

logFile = Agent2LogOvernightNew.csv
logFolder = Agent2Logs


[BatchLearn]
#Prior is either none or a thing

thetaFolder = jumper_11_21

thetaPrior  = none
thetaOutput = test.npy

logFile = Agent1LogRandOvernight.csv
logFolder = Agent1Logs

alpha = .01
gamma = .95
iterations = 10
